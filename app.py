import streamlit as st
import pandas as pd
import numpy as np
import pickle
import time
import sklearn
import plotly.express as px

# ==============================
# CONFIGURATION DE LA PAGE
# ==============================
st.set_page_config(
    page_title="IoT Intrusion Detection (RT-IoT2022)",
    page_icon="ğŸ›¡ï¸",
    layout="wide"
)

# ==============================
# CHARGEMENT DU MODÃˆLE
# ==============================
@st.cache_resource
def load_pipeline():
    with open("pipeline1.pkl", "rb") as f:
        pipeline = pickle.load(f)
    with open("final_model1.pkl", "rb") as f:
        label_encoder = pickle.load(f)
    return pipeline, label_encoder

pipeline, label_encoder = load_pipeline()

# ==============================
# HEADER PRINCIPAL
# ==============================
col1, col2 = st.columns([1, 3])  # ajuster la proportion
with col2:
# Titre et sous-titre
    st.title("ğŸ›¡ï¸ SystÃ¨me de DÃ©tection d'Intrusions IoT")
  

st.markdown("""
    ### Mini-projet ML
    Cette application utilise des **modÃ¨les de Machine Learning** pour dÃ©tecter
    les attaques rÃ©seau dans des environnements **IoT** Ã  partir du dataset **RT-IoT2022**.
    """)
  

# ==============================
# DICTIONNAIRE DES CLASSES
# ==============================
attack_type_dict = {
    'ARP_poisioning ğŸ–§': 0,
    'DDOS_Slowloris ğŸ’¥': 1,
    'DOS_SYN_Hping âš¡': 2,
    'MQTT_Publish ğŸ“¡': 3,
    'Metasploit_Brute_Force_SSH ğŸ”': 4,
    'NMAP_FIN_SCAN ğŸ•µï¸â€â™‚ï¸': 5,
    'NMAP_OS_DETECTION ğŸ–¥ï¸': 6,
    'NMAP_TCP_scan ğŸ”': 7,
    'NMAP_UDP_SCAN ğŸ§­': 8,
    'NMAP_XMAS_TREE_SCAN ğŸ„': 9,
    'Thing_Speak ğŸŒ': 10,
    'Wipro_bulb ğŸ’¡': 11
}

           
st.markdown("### ğŸ” Signification des classes **Attack_type**")
for attack, code in attack_type_dict.items():
    st.markdown(f"- **{attack}** : code = `{code}`")

st.divider()

# ==============================
# SIDEBAR
# ==============================
with st.sidebar:
    st.image(
        "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcShFS5Aos0PhDsLhfPJL6Irlm3GqgHD6bCCZg&s",
        width=250
    )
    st.header("ğŸ“¥ Chargement des donnÃ©es")
    uploaded_file = st.file_uploader(
        "Uploader un fichier CSV ou Excel",
        type=["csv", "xlsx"]
    )
    st.divider()
    st.subheader("ğŸ“ Contexte AcadÃ©mique")
    st.info("""
    **RÃ©alisÃ©e par :** Siham Bouzagrar  
    **Module :** Machine Learning / Data Science  
    **Encadrant :** Mr. Abdelhamid FADIL  
    
    """)

# ==============================
# TRAITEMENT DU FICHIER
# ==============================
if uploaded_file is not None:
    try:
        # --- Lecture du fichier ---
        if uploaded_file.name.endswith(".csv"):
            df = pd.read_csv(uploaded_file)
        else:
            df = pd.read_excel(uploaded_file)

        # --- Spinner & Progress Bar ---
        with st.spinner('Analyse du flux rÃ©seau en cours...'):
            progress_bar = st.progress(0)
            for percent_complete in range(100):
                time.sleep(0.01)
                progress_bar.progress(percent_complete + 1)

        # ==============================
        # STATISTIQUES
        # ==============================
        st.subheader("ğŸ“Š Statistiques des donnÃ©es chargÃ©es")
        col1, col2, col3 = st.columns(3)
        col1.metric("Nombre dâ€™instances", df.shape[0])
        col2.metric("Nombre de caractÃ©ristiques", df.shape[1])
        col3.metric("Type de classification", "Multi-classe")
        st.divider()

        # ==============================
        # APERÃ‡U DES DONNÃ‰ES
        # ==============================
        st.subheader("ğŸ“„ AperÃ§u des donnÃ©es")
        st.dataframe(df.head())
        st.divider()

        # ==============================
        # PRÃ‰DICTION
        # ==============================
        st.subheader("ğŸ¯ RÃ©sultats de la prÃ©diction")
        predictions = pipeline.predict(df)
        decoded_predictions = label_encoder.inverse_transform(predictions)

        st.success("âœ… L'analyse des intrusions est terminÃ©e avec succÃ¨s !")
        st.write("### Classe(s) prÃ©dite(s)")
        st.write(decoded_predictions)

        st.balloons()

        # ==============================
        # PROBABILITÃ‰S
        # ==============================
        if hasattr(pipeline.named_steps["classifier"], "predict_proba"):
            st.subheader("ğŸ“Š ProbabilitÃ©s de prÃ©diction")
            probs = pipeline.predict_proba(df)
            proba_df = pd.DataFrame(probs, columns=label_encoder.classes_)
            st.dataframe(proba_df)

        
          
           
    except Exception as e:
        st.error(f"âŒ Erreur lors du traitement du fichier : {e}")

else:
    st.info("â¡ï¸ Veuillez charger un fichier CSV ou Excel pour lancer la prÃ©diction.")
